{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TNI5HC\\.conda\\envs\\multimodel_rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "This function will be deprecated in a future release and `unstructured` will simply use the DEFAULT_MODEL from `unstructured_inference.model.base` to set default model name\n",
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from modules.ingestion.chunking import llmsherpa, unstructed_io\n",
    "\n",
    "name_file_pdf = 'finance_41pages.pdf'\n",
    "\n",
    "text = llmsherpa.chunking_to_get_text(name_file_pdf)\n",
    "table = unstructed_io.chunking_to_get_table_image(name_file_pdf, file_type='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text = [i['text'] for i in text]\n",
    "list_table = [i['text'] for i in table]\n",
    "\n",
    "list_text = list_text + list_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_url = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_url, device_map='cuda'\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_url, device_map='duda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "class ChunkDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.data[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.data[\"attention_mask\"][idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = tokenizer(list_text*10, max_length=256, truncation=True, padding=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChunkDataset(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(dataset,\n\u001b[0;32m      2\u001b[0m                         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      3\u001b[0m                         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m                         collate_fn\u001b[38;5;241m=\u001b[39mDataCollatorWithPadding(tokenizer))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=32,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=DataCollatorWithPadding(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 14, 384])\n",
      "torch.Size([2, 13, 384])\n",
      "torch.Size([2, 32, 384])\n",
      "torch.Size([2, 187, 384])\n",
      "torch.Size([2, 203, 384])\n",
      "torch.Size([2, 52, 384])\n",
      "torch.Size([2, 67, 384])\n",
      "torch.Size([2, 113, 384])\n",
      "torch.Size([2, 200, 384])\n",
      "torch.Size([2, 97, 384])\n",
      "torch.Size([2, 120, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 131, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 15, 384])\n",
      "torch.Size([2, 238, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 256, 384])\n",
      "torch.Size([2, 35, 384])\n",
      "torch.Size([2, 119, 384])\n",
      "torch.Size([2, 14, 384])\n",
      "torch.Size([2, 49, 384])\n",
      "torch.Size([2, 59, 384])\n",
      "torch.Size([2, 4, 384])\n",
      "torch.Size([2, 45, 384])\n",
      "torch.Size([2, 20, 384])\n",
      "torch.Size([2, 19, 384])\n",
      "torch.Size([2, 41, 384])\n",
      "torch.Size([2, 11, 384])\n",
      "torch.Size([2, 15, 384])\n",
      "torch.Size([2, 6, 384])\n",
      "torch.Size([2, 25, 384])\n",
      "torch.Size([2, 140, 384])\n",
      "torch.Size([2, 110, 384])\n",
      "torch.Size([2, 22, 384])\n",
      "torch.Size([2, 17, 384])\n",
      "torch.Size([2, 51, 384])\n",
      "torch.Size([2, 38, 384])\n",
      "torch.Size([2, 39, 384])\n",
      "torch.Size([2, 58, 384])\n",
      "torch.Size([2, 114, 384])\n",
      "torch.Size([2, 43, 384])\n",
      "torch.Size([2, 54, 384])\n",
      "torch.Size([2, 67, 384])\n",
      "torch.Size([2, 52, 384])\n",
      "torch.Size([2, 13, 384])\n",
      "torch.Size([2, 11, 384])\n",
      "torch.Size([2, 71, 384])\n",
      "torch.Size([2, 12, 384])\n",
      "torch.Size([2, 15, 384])\n",
      "torch.Size([2, 48, 384])\n",
      "torch.Size([2, 56, 384])\n",
      "torch.Size([2, 65, 384])\n",
      "torch.Size([2, 64, 384])\n",
      "torch.Size([2, 71, 384])\n",
      "torch.Size([2, 50, 384])\n",
      "torch.Size([2, 40, 384])\n",
      "torch.Size([2, 91, 384])\n",
      "torch.Size([2, 8, 384])\n",
      "torch.Size([2, 21, 384])\n",
      "torch.Size([2, 39, 384])\n",
      "torch.Size([2, 58, 384])\n",
      "torch.Size([2, 68, 384])\n",
      "torch.Size([2, 6, 384])\n",
      "torch.Size([2, 6, 384])\n",
      "torch.Size([2, 6, 384])\n",
      "torch.Size([2, 49, 384])\n",
      "torch.Size([2, 115, 384])\n",
      "torch.Size([2, 76, 384])\n",
      "torch.Size([2, 43, 384])\n",
      "torch.Size([2, 45, 384])\n",
      "torch.Size([2, 10, 384])\n",
      "torch.Size([2, 63, 384])\n",
      "torch.Size([2, 46, 384])\n",
      "torch.Size([2, 7, 384])\n",
      "torch.Size([2, 7, 384])\n",
      "torch.Size([2, 57, 384])\n",
      "torch.Size([2, 26, 384])\n",
      "torch.Size([2, 13, 384])\n",
      "torch.Size([2, 17, 384])\n",
      "torch.Size([2, 70, 384])\n",
      "torch.Size([2, 54, 384])\n",
      "torch.Size([2, 25, 384])\n",
      "torch.Size([2, 19, 384])\n",
      "torch.Size([2, 67, 384])\n",
      "torch.Size([2, 48, 384])\n",
      "torch.Size([2, 38, 384])\n",
      "torch.Size([2, 28, 384])\n",
      "torch.Size([2, 28, 384])\n",
      "torch.Size([2, 102, 384])\n",
      "torch.Size([2, 47, 384])\n",
      "torch.Size([2, 87, 384])\n",
      "torch.Size([2, 50, 384])\n",
      "torch.Size([2, 57, 384])\n",
      "torch.Size([2, 31, 384])\n",
      "torch.Size([2, 84, 384])\n",
      "torch.Size([2, 36, 384])\n",
      "torch.Size([2, 99, 384])\n",
      "torch.Size([2, 20, 384])\n",
      "torch.Size([2, 21, 384])\n",
      "torch.Size([2, 28, 384])\n",
      "torch.Size([2, 21, 384])\n",
      "torch.Size([2, 25, 384])\n",
      "torch.Size([2, 19, 384])\n",
      "torch.Size([2, 153, 384])\n",
      "torch.Size([2, 54, 384])\n",
      "torch.Size([2, 10, 384])\n",
      "torch.Size([2, 7, 384])\n",
      "torch.Size([2, 13, 384])\n",
      "torch.Size([2, 14, 384])\n",
      "torch.Size([2, 33, 384])\n",
      "torch.Size([2, 24, 384])\n",
      "torch.Size([2, 53, 384])\n",
      "torch.Size([2, 26, 384])\n",
      "torch.Size([2, 16, 384])\n",
      "torch.Size([2, 12, 384])\n",
      "torch.Size([2, 21, 384])\n",
      "torch.Size([2, 9, 384])\n",
      "torch.Size([2, 17, 384])\n",
      "torch.Size([2, 9, 384])\n",
      "torch.Size([2, 8, 384])\n",
      "torch.Size([2, 54, 384])\n",
      "torch.Size([2, 39, 384])\n",
      "torch.Size([2, 60, 384])\n",
      "torch.Size([2, 87, 384])\n",
      "torch.Size([2, 109, 384])\n",
      "torch.Size([2, 154, 384])\n",
      "torch.Size([2, 76, 384])\n",
      "torch.Size([2, 21, 384])\n",
      "torch.Size([2, 61, 384])\n",
      "torch.Size([2, 58, 384])\n",
      "torch.Size([2, 23, 384])\n",
      "torch.Size([2, 11, 384])\n",
      "torch.Size([2, 48, 384])\n",
      "torch.Size([2, 29, 384])\n",
      "torch.Size([2, 23, 384])\n",
      "torch.Size([2, 42, 384])\n",
      "torch.Size([2, 34, 384])\n",
      "torch.Size([2, 22, 384])\n",
      "torch.Size([2, 72, 384])\n",
      "torch.Size([2, 55, 384])\n",
      "torch.Size([2, 68, 384])\n",
      "torch.Size([2, 29, 384])\n",
      "torch.Size([2, 10, 384])\n",
      "torch.Size([2, 110, 384])\n",
      "torch.Size([2, 70, 384])\n",
      "torch.Size([2, 30, 384])\n",
      "torch.Size([2, 43, 384])\n",
      "torch.Size([2, 75, 384])\n",
      "torch.Size([2, 52, 384])\n",
      "torch.Size([2, 22, 384])\n",
      "torch.Size([2, 11, 384])\n",
      "torch.Size([2, 30, 384])\n",
      "torch.Size([2, 29, 384])\n",
      "torch.Size([2, 39, 384])\n",
      "torch.Size([2, 46, 384])\n",
      "torch.Size([2, 20, 384])\n",
      "torch.Size([2, 31, 384])\n",
      "torch.Size([2, 23, 384])\n",
      "torch.Size([2, 19, 384])\n",
      "torch.Size([2, 57, 384])\n",
      "torch.Size([2, 110, 384])\n",
      "torch.Size([2, 31, 384])\n",
      "torch.Size([2, 41, 384])\n",
      "torch.Size([2, 74, 384])\n",
      "torch.Size([2, 31, 384])\n",
      "torch.Size([2, 63, 384])\n",
      "torch.Size([2, 33, 384])\n",
      "torch.Size([2, 17, 384])\n",
      "torch.Size([2, 133, 384])\n",
      "torch.Size([2, 93, 384])\n",
      "torch.Size([2, 65, 384])\n",
      "torch.Size([2, 52, 384])\n",
      "torch.Size([2, 184, 384])\n",
      "torch.Size([2, 215, 384])\n",
      "torch.Size([2, 256, 384])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "\n",
    "    input_ids = batch['input_ids'].to('cuda')\n",
    "    attention_mask = batch['attention_mask'].to('cuda')\n",
    "\n",
    "    output = model(input_ids, attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
